ğŸ“˜ City Complaints â€“ End-to-End Cloud Data Engineering Project

AWS S3 â†’ Snowflake â†’ dbt â†’ (Power BI Ready)

This project demonstrates a complete, production-style data engineering workflow using modern cloud tools.
It ingests raw complaint data, loads it into a warehouse, transforms it into analytics-ready tables using dbt, and prepares it for BI dashboards.

ğŸš€ Architecture Overview
          CSV â†’ JSON
             â”‚
             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚     AWS S3     â”‚
     â”‚ Raw Data Lake  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Stage (S3)
             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Snowflake    â”‚
     â”‚   RAW Layer    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ dbt run
             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         dbt            â”‚
     â”‚  STG â†’ MARTS Models    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
       âœ” Power BI Ready

ğŸ“‚ Repository Structure
city_complaints_repo/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ s3/
â”‚   â””â”€â”€ data.json                # Sample data (GitHub-safe)
â”‚
â”œâ”€â”€ snowflake/
â”‚   â”œâ”€â”€ create.sql               # Database, file format, stage, raw table
â”‚   â”œâ”€â”€ load.sql                 # COPY INTO RAW table
â”‚   â””â”€â”€ analytics_examples.sql   # Example analytical queries
â”‚
â””â”€â”€ dbt/
    â”œâ”€â”€ dbt_project.yml
    â””â”€â”€ models/
        â”œâ”€â”€ sources.yml
        â”œâ”€â”€ schema.yml           # dbt tests
        â”œâ”€â”€ staging/
        â”‚   â””â”€â”€ stg_complaints.sql
        â””â”€â”€ marts/
            â”œâ”€â”€ fct_complaints.sql
            â”œâ”€â”€ dim_agency.sql
            â””â”€â”€ dim_location.sql

ğŸ—‚ Data Source

The original dataset is a complaint dataset (CSV).
It was converted into JSON and uploaded to an S3 bucket:

s3://<your-bucket-name>/data.json


Only a small sample is included in this repo for GitHub usage.

â„ Snowflake Setup
1. Create database, stage, and file format

Located in /snowflake/create.sql:

CREATE DATABASE CITY_COMPLAINTS_DB;
CREATE OR REPLACE FILE FORMAT json_ff TYPE = JSON STRIP_OUTER_ARRAY = TRUE;

CREATE OR REPLACE STAGE city_complaints_stage
  URL = 's3://<your-bucket>'
  CREDENTIALS = (
    AWS_KEY_ID = '<aws-key>'
    AWS_SECRET_KEY = '<aws-secret>'
  )
  FILE_FORMAT = json_ff;

2. Load JSON into RAW table

From /snowflake/load.sql:

COPY INTO RAW_COMPLAINTS
FROM @city_complaints_stage/data.json
FILE_FORMAT = (FORMAT_NAME = json_ff);

3. Validate
SELECT COUNT(*) FROM RAW_COMPLAINTS;

ğŸ§± dbt Project

The project includes:

âœ” Staging model

Cleans JSON data

Parses timestamps

Normalizes zip codes

Flattens nested fields

âœ” Marts layer

fct_complaints â€“ Fact table

dim_agency â€“ Dimension table

dim_location â€“ Location dimension

âœ” Tests (schema.yml)

not_null

unique

source tests

ğŸ§ª Running dbt
